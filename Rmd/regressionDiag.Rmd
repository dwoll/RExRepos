---
license: Creative Commons BY-SA
author: "Daniel Wollschlaeger"
title: "Regression diagnostics"
categories: [Univariate, Regression]
rerCat: Univariate
tags: [Regression]
---

Regression diagnostics
=========================

```{r echo=FALSE}
library(knitr)
opts_knit$set(self.contained=FALSE)
opts_chunk$set(tidy=FALSE, message=FALSE, warning=FALSE, comment=NA)
```

TODO
-------------------------

 - link to regression, regressionLogistic

Install required packages
-------------------------

[`car`](https://cran.r-project.org/package=car), [`lmtest`](https://cran.r-project.org/package=lmtest), [`mvoutlier`](https://cran.r-project.org/package=mvoutlier), [`perturb`](https://cran.r-project.org/package=perturb), [`robustbase`](https://cran.r-project.org/package=robustbase), [`tseries`](https://cran.r-project.org/package=tseries)

```{r}
wants <- c("car", "lmtest", "mvoutlier", "perturb", "robustbase", "tseries")
has   <- wants %in% rownames(installed.packages())
if(any(!has)) install.packages(wants[!has])
```

Extreme values and outliers
-------------------------
    
### Univariate assessment of outliers
    
```{r}
set.seed(123)
N  <- 100
X1 <- rnorm(N, 175, 7)
X2 <- rnorm(N,  30, 8)
X3 <- 0.3*X1 - 0.2*X2 + rnorm(N, 0, 5)
Y  <- 0.5*X1 - 0.3*X2 - 0.4*X3 + 10 + rnorm(N, 0, 5)
dfRegr <- data.frame(X1, X2, X3, Y)
```

```{r}
library(robustbase)
xyMat <- data.matrix(dfRegr)
robXY <- covMcd(xyMat)
XYz   <- scale(xyMat, center=robXY$center, scale=sqrt(diag(robXY$cov)))
summary(XYz)
```

### Multivariate assessment of outliers

Mahalanobis distance with robust estimate for the covariance matrix

```{r}
mahaSq <- mahalanobis(xyMat, center=robXY$center, cov=robXY$cov)
summary(sqrt(mahaSq))
```

Nonparametric multivariate outlier detection with package `mvoutlier`

```{r rerRegressionDiag01}
library(mvoutlier)
aqRes <- aq.plot(xyMat)
```

Where any outliers found?

```{r}
which(aqRes$outliers)
```

Leverage and influence
-------------------------

```{r}
fit <- lm(Y ~ X1 + X2 + X3, data=dfRegr)
h   <- hatvalues(fit)
summary(h)
```

```{r}
cooksDst <- cooks.distance(fit)
summary(cooksDst)
```

```{r}
inflRes <- influence.measures(fit)
summary(inflRes)
```

```{r rerRegressionDiag02}
library(car)
influenceIndexPlot(fit)
```

Checking model assumptions using residuals
-------------------------

```{r}
Estnd <- rstandard(fit)
Estud <- rstudent(fit)
```

### Normality assumption

```{r rerRegressionDiag03}
par(mar=c(5, 4.5, 4, 2)+0.1)
hist(Estud, main="Histogram studentized residals", breaks="FD", freq=FALSE)
curve(dnorm(x, mean=0, sd=1), col="red", lwd=2, add=TRUE)
```

```{r rerRegressionDiag04}
qqPlot(Estud, distribution="norm", pch=20, main="QQ-Plot studentized residuals")
qqline(Estud, col="red", lwd=2)
```

```{r}
shapiro.test(Estud)
```

### Independence and homoscedasticity assumption

#### Spread-level plot

```{r rerRegressionDiag05}
library(car)
spreadLevelPlot(fit, pch=20)
```

#### Durbin-Watson-test for autocorrelation

```{r}
library(car)
durbinWatsonTest(fit)
```

#### Statistical tests for heterocedasticity

Breusch-Pagan-Test

```{r}
library(lmtest)
bptest(fit)
```

Score-test for non-constant error variance

```{r}
library(car)
ncvTest(fit)
```

### Linearity assumption

White-test

```{r}
library(tseries)
white.test(dfRegr$X1, dfRegr$Y)
```

```{r results='hide'}
white.test(dfRegr$X2, dfRegr$Y)
white.test(dfRegr$X3, dfRegr$Y)
# not run
```

### Response transformations

```{r}
lamObj  <- powerTransform(fit, family="bcPower")
(lambda <- coef(lamObj))

library(car)
yTrans <- bcPower(dfRegr$Y, lambda)
```

Multicollinearity
-------------------------

### Pairwise correlations between predictor variables

```{r}
X   <- data.matrix(subset(dfRegr, select=c("X1", "X2", "X3")))
(Rx <- cor(X))
```

### Variance inflation factor

```{r}
library(car)
vif(fit)
```

### Condition indexes

\(\kappa\)

```{r}
fitScl <- lm(scale(Y) ~ scale(X1) + scale(X2) + scale(X3), data=dfRegr)
kappa(fitScl, exact=TRUE)
```

```{r}
library(perturb)
colldiag(fit, scale=TRUE, center=TRUE)
```

### Using package `perturb`

```{r}
pRes <- perturb(fit, pvars=c("X1", "X2", "X3"), prange=c(1, 1, 1))
summary(pRes)
```

Detach (automatically) loaded packages (if possible)
-------------------------

```{r}
try(detach(package:tseries))
try(detach(package:lmtest))
try(detach(package:zoo))
try(detach(package:perturb))
try(detach(package:mvoutlier))
try(detach(package:robustbase))
try(detach(package:sgeostat))
try(detach(package:car))
try(detach(package:carData))
```
